{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chunking Strategies\n",
<<<<<<< HEAD
    "In this notebook diffrent chunking mechanism is experimented on by making the other parameters constant in the simple rag pipeline to find the best chuncking mechanism.\n",
    "The chunking mechanisms are:\n",
=======
    "In this notebook, different chunking mechanisms are being experimented with by keeping the other parameters constant in the simple RAG pipeline, in order to find the best chunking mechanism.\n",
    "\n",
    "The idea behind this is that we need to chunk the documents, as we have a limited context window and larger documents will have high noise, which can distract the language model (LLM) from finding the relevant context. However, the chunking size also matters. We should be able to chunk documents with similar meaning together, so that the retriever will have enough chunks to provide to the LLM to answer the user's query.\n",
    "\n",
    "In the simple RAG pipeline, we have used recursive character chunking with a chunking size of 1000. In this notebook, we will experiment with smaller and larger chunking sizes for the recursive character chunking, as well as the semantic chunking mechanism, to improve the RAG performance.\n",
    "\n",
    "The chunking mechanisms being tested are:\n",
>>>>>>> evaluation
    "- Small Chunking size for recursive character chunking \n",
    "- larger chunking size for recursive character chunking\n",
    "- Semantic chunking mechanism\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import sys\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "sys.path.insert(1, '/home/jabez/week_11/Contract-Advisor-RAG')\n",
    "load_dotenv()\n",
    "sys.path.insert(1, '/home/jabez/rizzbuzz with poetry/RAG-Optimization-System/scripts')\n",
    "import file_loader \n",
    "import pipelines \n",
    "import evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "file_path = '/home/jabez/rizzbuzz with poetry/RAG-Optimization-System/data/cnn_dailymail_3.0.0.csv'\n",
    "data = file_loader.load_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RecursiveCharacterTextSplitter with 500 chunking size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this code for the first time after that the vectorstore will be saved in the chroma path\n",
    "# RecursiveCharacterTextSplitter with 500 chunking size\n",
    "chunk_size= 500\n",
    "chunk_overlap= 150\n",
    "vectorstore_character = file_loader.character_text_splitter(data, chunk_size, chunk_overlap)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
=======
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create or load a Chroma database\n",
    "embeddings = OpenAIEmbeddings()\n",
    "db = Chroma(persist_directory=\"/home/jabez/rizzbuzz with poetry/RAG-Optimization-System/vector_store\", embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
>>>>>>> evaluation
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading syntetic test data\n",
    "syntetic_test_data =pd.read_csv('/home/jabez/rizzbuzz with poetry/RAG-Optimization-System/test_data/syntetic_test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "retriver = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jabez/rizzbuzz with poetry/RAG-Optimization-System/.venv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# Adding answer to test data from simple pipeline\n",
    "syntetic_test_data_with_answer = evaluation.adding_answer_to_testdata(syntetic_test_data, pipelines.simple_pipeline, db, retriver)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
=======
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.arrow_dataset.Dataset"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(syntetic_test_data_with_answer)"
   ]
  },
  {
   "cell_type": "code",
>>>>>>> evaluation
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Evaluating:   1%|▏         | 1/80 [00:02<03:11,  2.42s/it]No statements were generated from the answer.\n",
      "Evaluating: 100%|██████████| 80/80 [00:37<00:00,  2.13it/s]\n"
=======
      "Evaluating:  82%|████████▎ | 66/80 [00:27<00:03,  3.90it/s]No statements were generated from the answer.\n",
      "Evaluating: 100%|██████████| 80/80 [00:33<00:00,  2.40it/s]\n"
>>>>>>> evaluation
     ]
    }
   ],
   "source": [
    "# Evaluating the test data from simple pipeline\n",
    "simple_rag_evaluation_result = evaluation.ragas_evaluator(syntetic_test_data_with_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "context_precision: 89.22%, faithfulness: 81.23%, answer_relevancy: 90.14%, context_recall: 79.33%\n"
=======
      "context_precision: 93.41%, faithfulness: 89.77%, answer_relevancy: 95.6%, context_recall: 88.33%\n"
>>>>>>> evaluation
     ]
    }
   ],
   "source": [
    "# Evaluation mean\n",
    "result = evaluation.evaluation_mean(simple_rag_evaluation_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context_precision</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.882616</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.970551</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.999299</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.775418</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.955961</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.926667</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.984427</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.916667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.943007</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.931690</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.883273</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.971916</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985173</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.948330</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.941903</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.946324</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.908949</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    context_precision  faithfulness  answer_relevancy  context_recall\n",
       "0            1.000000      0.600000          0.882616        1.000000\n",
       "1            1.000000      1.000000          0.970551        1.000000\n",
       "2            1.000000      0.909091          0.999299        1.000000\n",
       "3            1.000000      0.500000          1.000000        0.500000\n",
       "4            0.000000      0.000000          0.775418        0.000000\n",
       "5            1.000000      0.800000          1.000000        1.000000\n",
       "6            1.000000      1.000000          0.955961        1.000000\n",
       "7            0.926667      0.875000          0.984427        0.833333\n",
       "8            1.000000      1.000000          1.000000        1.000000\n",
       "9            0.916667      1.000000          1.000000        1.000000\n",
       "10           1.000000      0.750000          0.943007        1.000000\n",
       "11           1.000000      1.000000          0.000000        0.666667\n",
       "12           1.000000      1.000000          0.931690        1.000000\n",
       "13           1.000000           NaN          0.883273        0.666667\n",
       "14           1.000000      1.000000          0.971916        1.000000\n",
       "15           1.000000      1.000000          0.985173        1.000000\n",
       "16           1.000000      1.000000          0.948330        1.000000\n",
       "17           1.000000      1.000000          0.941903        1.000000\n",
       "18           1.000000      1.000000          0.946324        0.200000\n",
       "19           0.000000      0.000000          0.908949        0.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_rag_evaluation_result[['context_precision','faithfulness','answer_relevancy','context_recall']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RecursiveCharacterTextSplitter with 1000 chunking size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RecursiveCharacterTextSplitter with 1000 chunking size\n",
    "chunk_size= 1000\n",
    "chunk_overlap= 250\n",
    "vectorstore_character_large = file_loader.character_text_splitter(data, chunk_size, chunk_overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriver_large = vectorstore_character_large.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding answer to test data from simple pipeline\n",
    "syntetic_test_with_answer_large = evaluation.adding_answer_to_testdata(syntetic_test_data, pipelines.simple_pipeline, vectorstore_character_large, retriver_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 80/80 [00:40<00:00,  2.00it/s]\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the test data from simple pipeline\n",
    "simple_rag_large_evaluation_result = evaluation.ragas_evaluator(syntetic_test_with_answer_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision: 89.22%, faithfulness: 81.23%, answer_relevancy: 90.14%, context_recall: 79.33%\n"
     ]
    }
   ],
   "source": [
    "# Evaluation mean\n",
    "result = evaluation.evaluation_mean(simple_rag_evaluation_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision: 91.25%, faithfulness: 84.36%, answer_relevancy: 90.81%, context_recall: 82.92%\n"
     ]
    }
   ],
   "source": [
    "# Evaluation mean\n",
    "result = evaluation.evaluation_mean(simple_rag_large_evaluation_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Semantic Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting semantic text splitter\n",
    "vectorstore_semantic = file_loader.semantic_text_splitter(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting retriever for semantic based chuncking\n",
    "retriver_semantic = vectorstore_semantic.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding answer to test data from simple pipeline\n",
    "syntetic_test_data_with_answer = evaluation.adding_answer_to_testdata(syntetic_test_data, pipelines.simple_pipeline, vectorstore_semantic, retriver_semantic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 80/80 [00:55<00:00,  1.44it/s]\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the test data from simple pipeline\n",
    "simple_rag_evaluation_result = evaluation.ragas_evaluator(syntetic_test_data_with_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision: 90.02%, faithfulness: 80.08%, answer_relevancy: 77.02%, context_recall: 82.92%\n"
     ]
    }
   ],
   "source": [
    "# Evaluation mean\n",
    "result = evaluation.evaluation_mean(simple_rag_evaluation_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results:\n",
    "- Recursive Character Chunking with 500 chunk size:\n",
    "context_precision: 94.83%, faithfulness: 92.05%, answer_relevancy: 86.31%, context_recall: 90.5%\n",
    "- Recursive Character Chunking with 1000 chunk size:\n",
    "context_precision: 94.17%, faithfulness: 91.71%, answer_relevancy: 81.33%, context_recall: 76.83%\n",
    "- Semantic chunking result:\n",
    "context_precision: 90.02%, faithfulness: 80.08%, answer_relevancy: 77.02%, context_recall: 82.92%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
