{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chunking Strategies\n",
    "In this notebook, different chunking mechanisms are being experimented with by keeping the other parameters constant in the simple RAG pipeline, in order to find the best chunking mechanism.\n",
    "\n",
    "The idea behind this is that we need to chunk the documents, as we have a limited context window and larger documents will have high noise, which can distract the language model (LLM) from finding the relevant context. However, the chunking size also matters. We should be able to chunk documents with similar meaning together, so that the retriever will have enough chunks to provide to the LLM to answer the user's query.\n",
    "\n",
    "In the simple RAG pipeline, we have used recursive character chunking with a chunking size of 1000. In this notebook, we will experiment with smaller and larger chunking sizes for the recursive character chunking, as well as the semantic chunking mechanism, to improve the RAG performance.\n",
    "\n",
    "The chunking mechanisms being tested are:\n",
    "- Small Chunking size for recursive character chunking \n",
    "- larger chunking size for recursive character chunking\n",
    "- Semantic chunking mechanism\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import sys\n",
    "import json\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "load_dotenv()\n",
    "sys.path.insert(1, '/home/jabez/rizzbuzz with poetry/RAG-Optimization-System/scripts')\n",
    "import file_loader \n",
    "import pipelines \n",
    "import evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load JSON from file\n",
    "json_path = '../filepath.json'\n",
    "\n",
    "with open(json_path, 'r') as json_file:\n",
    "    file_paths = json.load(json_file)\n",
    "data_file_path = file_paths['data_file_path']\n",
    "synthetic_test_data_path = file_paths['synthetic_test_data_path']\n",
    "\n",
    "# loading data\n",
    "data = file_loader.load_csv(data_file_path)\n",
    "\n",
    "# loading synthetic test data\n",
    "synthetic_test_data = pd.read_csv(synthetic_test_data_path)\n",
    "\n",
    "# loading persist directory for smaller chunck vector db\n",
    "persist_directory_for_smaller_chunck_vector_db = file_paths['persist_directory_for_smaller_chunck_vector_db']\n",
    "\n",
    "# loading persist directory for larger chunck vector db\n",
    "persist_directory_for_larger_chunk_vector_db = file_paths['persist directory for larger_chunk_vector_db']\n",
    "\n",
    "# loading persist directory for semantic vector db\n",
    "persist_directory_for_semantic_vector_db = file_paths['persist_directory_for_semantic_vector_db']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RecursiveCharacterTextSplitter with 500 chunking size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a Chroma database\n",
    "embeddings = OpenAIEmbeddings()\n",
    "smaller_chunck_vector_db = Chroma(persist_directory=persist_directory_for_smaller_chunck_vector_db, embedding_function=embeddings)\n",
    "\n",
    "# Setting the retriever\n",
    "retriver = smaller_chunck_vector_db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})\n",
    "\n",
    "# Adding answer to test data from simple pipeline\n",
    "syntetic_test_data_with_answer = evaluation.adding_answer_to_testdata(synthetic_test_data, pipelines.simple_pipeline, smaller_chunck_vector_db, retriver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  82%|████████▎ | 66/80 [00:27<00:03,  3.90it/s]No statements were generated from the answer.\n",
      "Evaluating: 100%|██████████| 80/80 [00:33<00:00,  2.40it/s]\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the test data from simple pipeline\n",
    "simple_rag_evaluation_result = evaluation.ragas_evaluator(syntetic_test_data_with_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision: 93.41%, faithfulness: 89.77%, answer_relevancy: 95.6%, context_recall: 88.33%\n"
     ]
    }
   ],
   "source": [
    "# Evaluation mean\n",
    "result = evaluation.evaluation_mean(simple_rag_evaluation_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RecursiveCharacterTextSplitter with 1000 chunking size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_large = Chroma(persist_directory=persist_directory_for_larger_chunk_vector_db, embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriver_large = db_large.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jabez/rizzbuzz with poetry/RAG-Optimization-System/.venv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# Adding answer to test data from simple pipeline\n",
    "syntetic_test_data_with_answer = evaluation.adding_answer_to_testdata(synthetic_test_data, pipelines.simple_pipeline, db_large, retriver_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 80/80 [00:38<00:00,  2.09it/s]\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the test data from simple pipeline\n",
    "simple_rag_evaluation_result = evaluation.ragas_evaluator(syntetic_test_data_with_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision: 95.58%, faithfulness: 86.82%, answer_relevancy: 85.93%, context_recall: 88.92%\n"
     ]
    }
   ],
   "source": [
    "# Evaluation mean\n",
    "result = evaluation.evaluation_mean(simple_rag_evaluation_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Semantic Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore_semantic = file_loader.character_text_splitter_large_embedding(data, persist_directory_for_semantic_vector_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting semantic text splitter\n",
    "vectorstore_semantic = file_loader.semantic_text_splitter(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create or load a Chroma database\n",
    "embeddings = OpenAIEmbeddings()\n",
    "db_semantic = Chroma(persist_directory=persist_directory_for_semantic_vector_db, embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting retriever for semantic based chuncking\n",
    "retriver_semantic = db_semantic.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding answer to test data from simple pipeline\n",
    "syntetic_test_data_with_answer = evaluation.adding_answer_to_testdata(synthetic_test_data, pipelines.simple_pipeline, db_semantic, retriver_semantic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 80/80 [00:55<00:00,  1.44it/s]\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the test data from simple pipeline\n",
    "simple_rag_evaluation_result = evaluation.ragas_evaluator(syntetic_test_data_with_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision: 90.02%, faithfulness: 80.08%, answer_relevancy: 77.02%, context_recall: 82.92%\n"
     ]
    }
   ],
   "source": [
    "# Evaluation mean\n",
    "result = evaluation.evaluation_mean(simple_rag_evaluation_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results:\n",
    "- Recursive Character Chunking with 500 chunk size:\n",
    "context_precision: 94.83%, faithfulness: 92.05%, answer_relevancy: 86.31%, context_recall: 90.5%\n",
    "- Recursive Character Chunking with 1000 chunk size:\n",
    "context_precision: 94.17%, faithfulness: 91.71%, answer_relevancy: 81.33%, context_recall: 76.83%\n",
    "- Semantic chunking result:\n",
    "context_precision: 90.02%, faithfulness: 80.08%, answer_relevancy: 77.02%, context_recall: 82.92%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
