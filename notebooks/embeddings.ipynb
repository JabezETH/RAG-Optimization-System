{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embbeding Models\n",
    "In this notebook we are expermenting on two embedding models. One is the default text-embedding-ada-002 and the other is text-embedding-3-large. By improving the embedding model we can improve the relevancy of the retrived documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "sys.path.insert(1, '/home/jabez/week_11/Contract-Advisor-RAG')\n",
    "load_dotenv()\n",
    "sys.path.insert(1, '/home/jabez/rizzbuzz with poetry/RAG-Optimization-System/scripts')\n",
    "import file_loader \n",
    "import pipelines \n",
    "import evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "file_path = '/home/jabez/rizzbuzz with poetry/RAG-Optimization-System/data/cnn_dailymail_3.0.0.csv'\n",
    "data = file_loader.load_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### text-embedding-ada-002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create or load a Chroma database\n",
    "embeddings = OpenAIEmbeddings()\n",
    "db_default = Chroma(persist_directory=\"/home/jabez/rizzbuzz with poetry/RAG-Optimization-System/vector_store\", embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate syntetic test data\n",
    "file_path = '/home/jabez/rizzbuzz with poetry/RAG-Optimization-System/test_data/syntetic_test_data.csv'\n",
    "syntetic_test_data =evaluation.generate_syntetic_testdata(data, file_path)\n",
    "\n",
    "# Loading syntetic test data\n",
    "syntetic_test_data = pd.read_csv('/home/jabez/rizzbuzz with poetry/RAG-Optimization-System/test_data/syntetic_test_data.csv')\n",
    "\n",
    "# Setting retriever\n",
    "retriver = db_default.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jabez/rizzbuzz with poetry/RAG-Optimization-System/.venv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "Evaluating:  35%|███▌      | 28/80 [00:16<00:25,  2.05it/s]No statements were generated from the answer.\n",
      "Evaluating: 100%|██████████| 80/80 [00:34<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision: 89.93%, faithfulness: 84.82%, answer_relevancy: 82.21%, context_recall: 92.33%\n"
     ]
    }
   ],
   "source": [
    "# Adding answer to test data from simple pipeline\n",
    "file_path_with_answer = '/home/jabez/rizzbuzz with poetry/RAG-Optimization-System/test_data/syntetic_test_data_with_answer.csv'\n",
    "syntetic_test_data_with_answer = evaluation.adding_answer_to_testdata(syntetic_test_data, pipelines.simple_pipeline, db_default, retriver)\n",
    "\n",
    "# Evaluating the test data from simple pipeline\n",
    "simple_rag_evaluation_result = evaluation.ragas_evaluator(syntetic_test_data_with_answer)\n",
    "\n",
    "# Evaluation mean\n",
    "result = evaluation.evaluation_mean(simple_rag_evaluation_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### text-embedding-3-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the text splitter with the specified chunk size and overlap\n",
    "chunk_size= 500\n",
    "chunk_overlap= 150\n",
    "persist_directory = '/home/jabez/rizzbuzz with poetry/RAG-Optimization-System/text_embedding_large'\n",
    "vectorstore_character = file_loader.character_text_splitter_large_embedding(data, chunk_size, chunk_overlap, persist_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create or load a Chroma database\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "db_large = Chroma(persist_directory=\"/home/jabez/rizzbuzz with poetry/RAG-Optimization-System/text_embedding_large\", embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filename and doc_id are the same for all nodes.                     \n",
      "Generating: 100%|██████████| 20/20 [01:06<00:00,  3.35s/it]\n",
      "Evaluating:  42%|████▎     | 34/80 [00:17<00:18,  2.50it/s]No statements were generated from the answer.\n",
      "Evaluating: 100%|██████████| 80/80 [00:36<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision: 88.17%, faithfulness: 75.8%, answer_relevancy: 84.84%, context_recall: 80.42%\n"
     ]
    }
   ],
   "source": [
    "# Generate syntetic test data\n",
    "file_path = '/home/jabez/rizzbuzz with poetry/RAG-Optimization-System/test_data/syntetic_test_data.csv'\n",
    "syntetic_test_data =evaluation.generate_syntetic_testdata(data, file_path)\n",
    "\n",
    "# Loading syntetic test data\n",
    "syntetic_test_data = pd.read_csv('/home/jabez/rizzbuzz with poetry/RAG-Optimization-System/test_data/syntetic_test_data.csv')\n",
    "\n",
    "# Setting retriever\n",
    "retriver = vectorstore_character.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})\n",
    "\n",
    "# Adding answer to test data from simple pipeline\n",
    "file_path_with_answer = '/home/jabez/rizzbuzz with poetry/RAG-Optimization-System/test_data/syntetic_test_data_with_answer.csv'\n",
    "syntetic_test_data_with_answer = evaluation.adding_answer_to_testdata(syntetic_test_data, pipelines.simple_pipeline, vectorstore_character, retriver)\n",
    "\n",
    "# Evaluating the test data from simple pipeline\n",
    "simple_rag_evaluation_result = evaluation.ragas_evaluator(syntetic_test_data_with_answer)\n",
    "\n",
    "# Evaluation mean\n",
    "result = evaluation.evaluation_mean(simple_rag_evaluation_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
