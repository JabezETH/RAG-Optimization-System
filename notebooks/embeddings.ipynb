{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embbeding Models\n",
    "In this notebook we are expermenting on two embedding models. One is the default text-embedding-ada-002 and the other is text-embedding-3-large. By improving the embedding model we can improve the relevancy of the retrived documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jabez/rizzbuzz with poetry/RAG-Optimization-System/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Importing libraries\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "sys.path.insert(1, '/home/jabez/week_11/Contract-Advisor-RAG')\n",
    "load_dotenv()\n",
    "sys.path.insert(1, '/home/jabez/rizzbuzz with poetry/RAG-Optimization-System/scripts')\n",
    "import file_loader \n",
    "import pipelines \n",
    "import evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load JSON from file\n",
    "json_path = '../filepath.json'\n",
    "\n",
    "with open(json_path, 'r') as json_file:\n",
    "    file_paths = json.load(json_file)\n",
    "data_file_path = file_paths['data_file_path']\n",
    "synthetic_test_data_path = file_paths['synthetic_test_data_path']\n",
    "\n",
    "# loading data\n",
    "data = file_loader.load_csv(data_file_path)\n",
    "\n",
    "# loading synthetic test data\n",
    "synthetic_test_data = pd.read_csv(synthetic_test_data_path)\n",
    "\n",
    "# loading persist directory for smaller chunck vector db\n",
    "persist_directory_for_smaller_chunck_vector_db = file_paths['persist_directory_for_smaller_chunck_vector_db']\n",
    "\n",
    "# loading persist directory for larger chunck vector db\n",
    "persist_directory_for_larger_chunk_vector_db = file_paths['persist_directory_for_larger_chunk_vector_db']\n",
    "\n",
    "# loading persist directory for semantic vector db\n",
    "persist_directory_for_semantic_vector_db = file_paths['persist_directory_for_semantic_vector_db']\n",
    "\n",
    "# loading persist directory for deafult vector db\n",
    "persist_directory_for_default_vector_db = file_paths['persist_directory_for_default_vector_db']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### text-embedding-ada-002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create or load a Chroma database\n",
    "embeddings = OpenAIEmbeddings()\n",
    "db_default = Chroma(persist_directory=persist_directory_for_default_vector_db, embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jabez/rizzbuzz with poetry/RAG-Optimization-System/.venv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "Evaluating:   1%|▏         | 1/80 [00:04<05:40,  4.31s/it]Failed to batch ingest runs: LangSmithRateLimitError('Rate limit exceeded for https://api.smith.langchain.com/runs/batch. HTTPError(\\'429 Client Error: Too Many Requests for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Monthly unique traces usage limit exceeded\"}\\')')\n",
      "Evaluating:  69%|██████▉   | 55/80 [00:40<00:14,  1.78it/s]Failed to batch ingest runs: LangSmithConnectionError(\"Connection error caused failure to POST https://api.smith.langchain.com/runs/batch  in LangSmith API. Please confirm your internet connection.. ConnectionError(ProtocolError('Connection aborted.', TimeoutError('The write operation timed out')))\")\n",
      "Evaluating: 100%|██████████| 80/80 [00:56<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision: 86.73%, faithfulness: 78.12%, answer_relevancy: 90.59%, context_recall: 74.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to batch ingest runs: LangSmithConnectionError(\"Connection error caused failure to POST https://api.smith.langchain.com/runs/batch  in LangSmith API. Please confirm your internet connection.. ConnectionError(ProtocolError('Connection aborted.', TimeoutError('The write operation timed out')))\")\n",
      "Failed to batch ingest runs: LangSmithConnectionError(\"Connection error caused failure to POST https://api.smith.langchain.com/runs/batch  in LangSmith API. Please confirm your internet connection.. ConnectionError(ProtocolError('Connection aborted.', TimeoutError('The write operation timed out')))\")\n",
      "Failed to batch ingest runs: LangSmithConnectionError(\"Connection error caused failure to POST https://api.smith.langchain.com/runs/batch  in LangSmith API. Please confirm your internet connection.. ConnectionError(ProtocolError('Connection aborted.', TimeoutError('The write operation timed out')))\")\n",
      "Failed to batch ingest runs: LangSmithConnectionError(\"Connection error caused failure to POST https://api.smith.langchain.com/runs/batch  in LangSmith API. Please confirm your internet connection.. ConnectionError(ProtocolError('Connection aborted.', TimeoutError('The write operation timed out')))\")\n",
      "Failed to batch ingest runs: LangSmithConnectionError('Connection error caused failure to POST https://api.smith.langchain.com/runs/batch  in LangSmith API. Please confirm your internet connection.. SSLError(MaxRetryError(\"HTTPSConnectionPool(host=\\'api.smith.langchain.com\\', port=443): Max retries exceeded with url: /runs/batch (Caused by SSLError(SSLEOFError(8, \\'EOF occurred in violation of protocol (_ssl.c:2426)\\')))\"))')\n",
      "Failed to batch ingest runs: LangSmithConnectionError(\"Connection error caused failure to POST https://api.smith.langchain.com/runs/batch  in LangSmith API. Please confirm your internet connection.. ConnectionError(ProtocolError('Connection aborted.', TimeoutError('The write operation timed out')))\")\n",
      "Failed to batch ingest runs: ReadTimeout(ReadTimeoutError(\"HTTPSConnectionPool(host='api.smith.langchain.com', port=443): Read timed out. (read timeout=10.0)\"))\n",
      "Failed to batch ingest runs: LangSmithConnectionError(\"Connection error caused failure to POST https://api.smith.langchain.com/runs/batch  in LangSmith API. Please confirm your internet connection.. ConnectionError(ProtocolError('Connection aborted.', TimeoutError('The write operation timed out')))\")\n",
      "Failed to batch ingest runs: LangSmithConnectionError(\"Connection error caused failure to POST https://api.smith.langchain.com/runs/batch  in LangSmith API. Please confirm your internet connection.. ConnectionError(ProtocolError('Connection aborted.', TimeoutError('The write operation timed out')))\")\n"
     ]
    }
   ],
   "source": [
    "# Setting retriever\n",
    "retriver = db_default.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})\n",
    "\n",
    "# Adding answer to test data from simple pipeline\n",
    "file_path_with_answer = '/home/jabez/rizzbuzz with poetry/RAG-Optimization-System/test_data/syntetic_test_data_with_answer.csv'\n",
    "syntetic_test_data_with_answer = evaluation.adding_answer_to_testdata(synthetic_test_data, pipelines.simple_pipeline, db_default, retriver)\n",
    "\n",
    "# Evaluating the test data from simple pipeline\n",
    "simple_rag_evaluation_result = evaluation.ragas_evaluator(syntetic_test_data_with_answer)\n",
    "\n",
    "# Evaluation mean\n",
    "result = evaluation.evaluation_mean(simple_rag_evaluation_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### text-embedding-3-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create or load a Chroma database\n",
    "embeddings = OpenAIEmbeddings()\n",
    "db_large = Chroma(persist_directory=persist_directory_for_smaller_chunck_vector_db, embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filename and doc_id are the same for all nodes.                     \n",
      "Generating: 100%|██████████| 20/20 [01:06<00:00,  3.35s/it]\n",
      "Evaluating:  42%|████▎     | 34/80 [00:17<00:18,  2.50it/s]No statements were generated from the answer.\n",
      "Evaluating: 100%|██████████| 80/80 [00:36<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_precision: 88.17%, faithfulness: 75.8%, answer_relevancy: 84.84%, context_recall: 80.42%\n"
     ]
    }
   ],
   "source": [
    "# Generate syntetic test data\n",
    "file_path = '/home/jabez/rizzbuzz with poetry/RAG-Optimization-System/test_data/syntetic_test_data.csv'\n",
    "syntetic_test_data =evaluation.generate_syntetic_testdata(data, file_path)\n",
    "\n",
    "# Loading syntetic test data\n",
    "syntetic_test_data = pd.read_csv('/home/jabez/rizzbuzz with poetry/RAG-Optimization-System/test_data/syntetic_test_data.csv')\n",
    "\n",
    "# Setting retriever\n",
    "retriver = db_large.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})\n",
    "\n",
    "# Adding answer to test data from simple pipeline\n",
    "file_path_with_answer = '/home/jabez/rizzbuzz with poetry/RAG-Optimization-System/test_data/syntetic_test_data_with_answer.csv'\n",
    "syntetic_test_data_with_answer = evaluation.adding_answer_to_testdata(syntetic_test_data, pipelines.simple_pipeline, vectorstore_character, retriver)\n",
    "\n",
    "# Evaluating the test data from simple pipeline\n",
    "simple_rag_evaluation_result = evaluation.ragas_evaluator(syntetic_test_data_with_answer)\n",
    "\n",
    "# Evaluation mean\n",
    "result = evaluation.evaluation_mean(simple_rag_evaluation_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
